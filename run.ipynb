{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3a65fb-8def-459a-86ff-14f5cf3bc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from implementations import *\n",
    "from helpers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c729a004-595c-4d58-bbcb-b0f304e22f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb42fca-b128-48c4-891b-14abf08cb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_raw, train_data_raw, train_ids = load_csv_data(\"data/train.csv\")\n",
    "_, test_data_raw, test_ids = load_csv_data(\"data/train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df84222-7f1e-4c5f-ad53-a73f0b005a97",
   "metadata": {},
   "source": [
    "Code for visualisation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582f886e-6d8c-4453-87cb-8613ef3eef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000\n",
      "211886\n",
      "(250000, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>211886.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>121.858528</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>2.403735</td>\n",
       "      <td>371.783360</td>\n",
       "      <td>-0.821688</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>158.432217</td>\n",
       "      <td>1.437609</td>\n",
       "      <td>-0.128305</td>\n",
       "      <td>0.458290</td>\n",
       "      <td>38.707419</td>\n",
       "      <td>-0.010973</td>\n",
       "      <td>-0.008171</td>\n",
       "      <td>46.660207</td>\n",
       "      <td>-0.019507</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>41.717235</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>84.822105</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>-0.012393</td>\n",
       "      <td>57.679474</td>\n",
       "      <td>-0.011845</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>57.298157</td>\n",
       "      <td>35.344886</td>\n",
       "      <td>40.828691</td>\n",
       "      <td>63.655682</td>\n",
       "      <td>1.742226</td>\n",
       "      <td>397.699325</td>\n",
       "      <td>3.584362</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>22.273494</td>\n",
       "      <td>115.706115</td>\n",
       "      <td>0.844743</td>\n",
       "      <td>1.193585</td>\n",
       "      <td>0.398681</td>\n",
       "      <td>22.412081</td>\n",
       "      <td>1.214079</td>\n",
       "      <td>1.816763</td>\n",
       "      <td>22.064922</td>\n",
       "      <td>1.264982</td>\n",
       "      <td>1.816611</td>\n",
       "      <td>32.894693</td>\n",
       "      <td>1.812223</td>\n",
       "      <td>126.499506</td>\n",
       "      <td>0.977426</td>\n",
       "      <td>60.662276</td>\n",
       "      <td>1.784546</td>\n",
       "      <td>1.813385</td>\n",
       "      <td>31.985782</td>\n",
       "      <td>2.031743</td>\n",
       "      <td>1.816950</td>\n",
       "      <td>98.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.044000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.602000</td>\n",
       "      <td>-18.066000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.104000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>-1.414000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-2.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>-2.505000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>91.885250</td>\n",
       "      <td>19.241000</td>\n",
       "      <td>59.388750</td>\n",
       "      <td>14.068750</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>111.977000</td>\n",
       "      <td>-2.629000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.841000</td>\n",
       "      <td>77.550000</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>-1.371000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>24.591750</td>\n",
       "      <td>-0.925000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>32.375000</td>\n",
       "      <td>-1.014000</td>\n",
       "      <td>-1.522000</td>\n",
       "      <td>21.398000</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>123.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.422500</td>\n",
       "      <td>-1.342000</td>\n",
       "      <td>-1.584000</td>\n",
       "      <td>37.312000</td>\n",
       "      <td>-1.612000</td>\n",
       "      <td>-1.576500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>112.406000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>2.107000</td>\n",
       "      <td>225.885000</td>\n",
       "      <td>-0.244000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>120.664500</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>31.804000</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>40.516000</td>\n",
       "      <td>-0.045000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>34.802000</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.561000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>47.902000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.002000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>135.482000</td>\n",
       "      <td>73.598000</td>\n",
       "      <td>92.259000</td>\n",
       "      <td>79.169000</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>478.226000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>27.591000</td>\n",
       "      <td>200.478250</td>\n",
       "      <td>1.777000</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>45.017000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>1.565000</td>\n",
       "      <td>53.390000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>1.618000</td>\n",
       "      <td>51.895000</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>263.379250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>103.342000</td>\n",
       "      <td>1.336000</td>\n",
       "      <td>1.562000</td>\n",
       "      <td>66.637000</td>\n",
       "      <td>1.589500</td>\n",
       "      <td>1.576000</td>\n",
       "      <td>109.933750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>1852.462000</td>\n",
       "      <td>19.773000</td>\n",
       "      <td>1.414000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>764.408000</td>\n",
       "      <td>2.497000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>560.271000</td>\n",
       "      <td>2.503000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2842.617000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1              2              3   \\\n",
       "count  211886.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean      121.858528      49.239819      81.181982      57.895962   \n",
       "std        57.298157      35.344886      40.828691      63.655682   \n",
       "min         9.044000       0.000000       6.329000       0.000000   \n",
       "25%        91.885250      19.241000      59.388750      14.068750   \n",
       "50%       112.406000      46.524000      73.752000      38.467500   \n",
       "75%       135.482000      73.598000      92.259000      79.169000   \n",
       "max      1192.026000     690.075000    1349.351000    2834.999000   \n",
       "\n",
       "                 4             5             6              7              8   \\\n",
       "count  72543.000000  72543.000000  72543.000000  250000.000000  250000.000000   \n",
       "mean       2.403735    371.783360     -0.821688       2.373100      18.917332   \n",
       "std        1.742226    397.699325      3.584362       0.782911      22.273494   \n",
       "min        0.000000     13.602000    -18.066000       0.208000       0.000000   \n",
       "25%        0.882500    111.977000     -2.629000       1.810000       2.841000   \n",
       "50%        2.107000    225.885000     -0.244000       2.491500      12.315500   \n",
       "75%        3.690000    478.226000      0.958000       2.961000      27.591000   \n",
       "max        8.503000   4974.979000     16.690000       5.684000    2834.999000   \n",
       "\n",
       "                  9              10             11            12  \\\n",
       "count  250000.000000  250000.000000  250000.000000  72543.000000   \n",
       "mean      158.432217       1.437609      -0.128305      0.458290   \n",
       "std       115.706115       0.844743       1.193585      0.398681   \n",
       "min        46.104000       0.047000      -1.414000      0.000000   \n",
       "25%        77.550000       0.883000      -1.371000      0.004000   \n",
       "50%       120.664500       1.280000      -0.356000      0.454000   \n",
       "75%       200.478250       1.777000       1.225000      0.879000   \n",
       "max      1852.462000      19.773000       1.414000      1.000000   \n",
       "\n",
       "                  13             14             15             16  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean       38.707419      -0.010973      -0.008171      46.660207   \n",
       "std        22.412081       1.214079       1.816763      22.064922   \n",
       "min        20.000000      -2.499000      -3.142000      26.000000   \n",
       "25%        24.591750      -0.925000      -1.575000      32.375000   \n",
       "50%        31.804000      -0.023000      -0.033000      40.516000   \n",
       "75%        45.017000       0.898000       1.565000      53.390000   \n",
       "max       764.408000       2.497000       3.142000     560.271000   \n",
       "\n",
       "                  17             18             19             20  \\\n",
       "count  250000.000000  250000.000000  250000.000000  250000.000000   \n",
       "mean       -0.019507       0.043543      41.717235      -0.010119   \n",
       "std         1.264982       1.816611      32.894693       1.812223   \n",
       "min        -2.505000      -3.142000       0.109000      -3.142000   \n",
       "25%        -1.014000      -1.522000      21.398000      -1.575000   \n",
       "50%        -0.045000       0.086000      34.802000      -0.024000   \n",
       "75%         0.959000       1.618000      51.895000       1.561000   \n",
       "max         2.503000       3.142000    2842.617000       3.142000   \n",
       "\n",
       "                  21             22             23             24  \\\n",
       "count  250000.000000  250000.000000  150087.000000  150087.000000   \n",
       "mean      209.797178       0.979176      84.822105      -0.003275   \n",
       "std       126.499506       0.977426      60.662276       1.784546   \n",
       "min        13.678000       0.000000      30.000000      -4.499000   \n",
       "25%       123.017500       0.000000      44.422500      -1.342000   \n",
       "50%       179.739000       1.000000      65.561000       0.000000   \n",
       "75%       263.379250       2.000000     103.342000       1.336000   \n",
       "max      2003.976000       3.000000    1120.573000       4.499000   \n",
       "\n",
       "                  25            26            27            28             29  \n",
       "count  150087.000000  72543.000000  72543.000000  72543.000000  250000.000000  \n",
       "mean       -0.012393     57.679474     -0.011845     -0.001582      73.064591  \n",
       "std         1.813385     31.985782      2.031743      1.816950      98.015662  \n",
       "min        -3.142000     30.000000     -4.500000     -3.142000       0.000000  \n",
       "25%        -1.584000     37.312000     -1.612000     -1.576500       0.000000  \n",
       "50%        -0.033000     47.902000     -0.010000     -0.002000      40.512500  \n",
       "75%         1.562000     66.637000      1.589500      1.576000     109.933750  \n",
       "max         3.141000    721.456000      4.500000      3.142000    1633.433000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=train_data_raw, index=None, columns=None)\n",
    "df = df.applymap(lambda v: v if v > -999.0 else np.NaN)\n",
    "print(len(df))\n",
    "two_more_jets = df[(df[[22]] >= 2).to_numpy()].dropna()\n",
    "one_jet = df[(df[[22]] == 1).to_numpy()].drop([4,5,6,12,22,26,27,28,29], axis=1).dropna()\n",
    "zero_jet = df[(df[[22]] == 0).to_numpy()].drop([4,5,6,12,22,23,24,25,26,27,28,29], axis=1).dropna()\n",
    "print(len(two_more_jets)+len(one_jet)+len(zero_jet))\n",
    "print(test_data_raw.shape)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8226b5-292a-4fea-9a8e-63294246442e",
   "metadata": {},
   "source": [
    "## Data cleaning and grouping\n",
    "This part creates three sets of rows depending on the number of jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5b771a-a00b-4249-b904-7e65483e7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_over = train_data_raw[train_data_raw[:,0] != -999]\n",
    "med_DER_mass_MMC = np.median(med_over[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c8c699-642d-4806-bb8f-d0da7a56dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_raw[train_data_raw[:,0] > -999].copy()\n",
    "means = np.nanmean(train_data, axis=0)\n",
    "inds = np.where(np.isnan(train_data))\n",
    "train_data[inds] = np.take(means, inds[1])\n",
    "\n",
    "train_labels = train_labels_raw[train_data_raw[:,0] > -999].copy()\n",
    "\n",
    "test_data = test_data_raw.copy()\n",
    "test_data[test_data_raw[:,0] == -999] = med_DER_mass_MMC\n",
    "inds = np.where(np.isnan(test_data))\n",
    "test_data[inds] = np.take(means, inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55538e76-e371-4d6f-ae76-03c72ed0736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_more_jets = train_data[train_data[:,22] >= 2].copy()\n",
    "one_jet = train_data[train_data[:,22] == 1].copy()\n",
    "one_jet = np.delete(one_jet, np.s_[4,5,6,12,22,26,27,28,29], axis=1)\n",
    "zero_jet = train_data[train_data[:,22] == 0].copy()\n",
    "zero_jet = np.delete(zero_jet, np.s_[4,5,6,12,22,23,24,25,26,27,28,29], axis=1)\n",
    "\n",
    "jet_sets = [zero_jet, one_jet, two_more_jets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20b4f370-0be2-429e-9e51-ff82f84948c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_more_jets = train_labels[train_data[:,22] >= 2].copy()\n",
    "one_jet = train_labels[train_data[:,22] == 1].copy()\n",
    "zero_jet = train_labels[train_data[:,22] == 0].copy()\n",
    "\n",
    "jet_sets_labels = [zero_jet, one_jet, two_more_jets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81f6220d-8c59-40d6-b8ea-66992b8bdf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_more_jets_test = test_data[test_data[:,22] >= 2].copy()\n",
    "one_jet_test = test_data[test_data[:,22] == 1].copy()\n",
    "one_jet_test = np.delete(one_jet_test, np.s_[4,5,6,12,22,26,27,28,29], axis=1)\n",
    "zero_jet_test = test_data[test_data[:,22] == 0].copy()\n",
    "zero_jet_test = np.delete(zero_jet_test, np.s_[4,5,6,12,22,23,24,25,26,27,28,29], axis=1)\n",
    "\n",
    "\n",
    "jet_sets_test = [zero_jet_test, one_jet_test, two_more_jets_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba182e-44e4-492d-baf4-af3d4a169dcf",
   "metadata": {},
   "source": [
    "### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba899f82-6863-44cb-acd3-0aee5f4e52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    mean = jet_sets[i].mean(axis=0)\n",
    "    std = jet_sets[i].std(axis=0)\n",
    "    jet_sets[i] = (jet_sets[i] - mean)/std\n",
    "    jet_sets_test[i] = (jet_sets_test[i] - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7752cf4-a4c3-4eef-98ef-4288ac8d1c6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a3dcd-aaa0-46dd-b54e-e2a6329012fd",
   "metadata": {},
   "source": [
    "functions to test different methods for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdbe4f29-56e7-4f6d-b3d3-8e9b5b0b04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, model):\n",
    "    \"\"\"\n",
    "    compute the proportion of misprediction\n",
    "    \"\"\"\n",
    "    pred = tx @ model\n",
    "    decision = 0\n",
    "    pred[np.where(pred <  decision)] = -1\n",
    "    pred[np.where(pred >= decision)] = 1\n",
    "    err = (pred - y)/2\n",
    "    return np.absolute(err).mean()\n",
    "\n",
    "def build_validation_sets(y, k_fold, seed):\n",
    "    \"\"\"\n",
    "    returns indices for a train set and a test set\n",
    "    \"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    return indices[indices.shape[0]//(k_fold+1):], indices[:indices.shape[0]//(k_fold+1)],\n",
    "\n",
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\n",
    "    \n",
    "    Args:\n",
    "        x: numpy array of shape (N,D)\n",
    "        degree: integer.\n",
    "        \n",
    "    Returns:\n",
    "        poly: numpy array of shape (N,D*d+1)\n",
    "    \"\"\"    \n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    #poly_base = np.zeros((N, D*degree + 1))\n",
    "    poly_base = np.ones((N,1))\n",
    "    poly_base = np.hstack((poly_base, x.copy()))\n",
    "    for i in range(degree-1):\n",
    "        range_start = 1 + i*D\n",
    "        range_stop = 1 + (i+1)*D\n",
    "        next_power = poly_base[:,range_start:range_stop]*x\n",
    "        poly_base = np.hstack((poly_base, next_power))\n",
    "    \n",
    "    return poly_base\n",
    "\n",
    "def cross_validation(y, x, train_model, degree):\n",
    "    \"\"\"\n",
    "    Tests a certain training function using 4-fold cross-validation\n",
    "    arguments: \n",
    "    train_model: func(y, tx) -> model\n",
    "    returns: model, training_loss, test_loss\n",
    "    \"\"\"\n",
    "    tx = build_poly(x, degree)\n",
    "    k = 4\n",
    "    train_idx, test_idx = build_validation_sets(x, k, seed)\n",
    "    model, train_loss = train_model(y[train_idx], tx[train_idx])\n",
    "    test_loss = compute_loss(y[test_idx], tx[test_idx], model)\n",
    "    return model, train_loss, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f2073-be82-49c6-9b9b-1445a1baaf91",
   "metadata": {},
   "source": [
    "Graph stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dcf262e-d3ff-471e-9e97-17b158776551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cross_validation_visualization(lambds, mse_tr, mse_te):\n",
    "    \"\"\"visualization the curves of mse_tr and mse_te.\"\"\"\n",
    "    plt.semilogx(lambds, mse_tr, marker=\".\", color='b', label='train error')\n",
    "    plt.semilogx(lambds, mse_te, marker=\".\", color='r', label='test error')\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"r mse\")\n",
    "    #plt.xlim(1e-4, 1)\n",
    "    plt.title(\"cross validation\")\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(True)\n",
    "    \n",
    "def cross_validation_explore_lambda(y_, x_, train_model, degree, lambdas):\n",
    "    \"\"\"cross validation over regularisation parameter lambda.\n",
    "    \n",
    "    Args:\n",
    "        train_model: func(y, tx, lambda) -> model\n",
    "        degree: integer, degree of the polynomial expansion\n",
    "        lambdas: shape = (p, ) where p is the number of values of lambda to test\n",
    "    Returns:\n",
    "        best_lambda : scalar, value of the best lambda\n",
    "        best_mse : scalar, the associated mean squared error for the best lambda\n",
    "    \"\"\"\n",
    "    seed = 12\n",
    "    degree = degree\n",
    "    lambdas = lambdas\n",
    "    # define lists to store the loss of training data and test data\n",
    "    mse_tr = []\n",
    "    mse_te = []\n",
    "    \n",
    "    best_idx = 0\n",
    "    idx = 0\n",
    "    for lambda_ in np.nditer(lambdas):\n",
    "        _, te, tr = cross_validation(y_, x_, lambda y,tx: train_model(y,tx, lambda_), degree)\n",
    "        mse_tr.append(tr)\n",
    "        mse_te.append(te)\n",
    "        if te < mse_te[best_idx]:\n",
    "            best_idx = idx\n",
    "        idx += 1\n",
    "    \n",
    "    best_lambda = lambdas[best_idx]\n",
    "    best_mse = mse_te[best_idx]\n",
    "        \n",
    "    cross_validation_visualization(lambdas, mse_tr, mse_te)\n",
    "    print(\"For polynomial expansion up to degree %.f, the choice of lambda which leads to the best test mse is %.5f with a test mse of %.3f\" % (degree, best_lambda, best_mse))\n",
    "    return best_lambda, best_mse\n",
    "\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "#best_lambda, best_rmse = cross_validation_demo(7, 4, np.logspace(-4, 0, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ca23c-c1ac-4785-93b3-f324f71a9efe",
   "metadata": {},
   "source": [
    "Now try different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7976330-0c73-40a8-b4c3-24c6aed3aa41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24999410057342425"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_all = 2\n",
    "model_all, train_loss, test_loss = cross_validation(train_labels, train_data,least_squares, degree_all)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9ebb8fe-4d8d-446e-8d55-17ec3da49300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21554411166824772"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree0 = 1\n",
    "model0, train_loss, test_loss = cross_validation(jet_sets_labels[0], jet_sets[0],least_squares, degree0)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f49995bf-9b34-4e80-a426-ea6b4e89f118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22863675335810232"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree1 = 6\n",
    "model1, train_loss, test_loss = cross_validation(jet_sets_labels[1], jet_sets[1],least_squares,degree1)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9de94960-840e-4bbf-8e38-deb4ac9b29f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20305388342387315"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree2 = 4\n",
    "model2, train_loss, test_loss = cross_validation(jet_sets_labels[2], jet_sets[2],least_squares, degree2)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8659ee-f4c9-4539-bd39-c8ba83b8b1ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Applying the models to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95758cb2-802f-40a9-b6c6-a3cdbe3d1f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_predictions(test_sets, degrees, models):\n",
    "    assert test_data.shape[0] == test_sets[0].shape[0] + test_sets[1].shape[0] + test_sets[2].shape[0]\n",
    "    test_sets_expanded = {}\n",
    "    for i in range(3):\n",
    "        test_sets_expanded[i] = build_poly(test_sets[i], degrees[i])\n",
    "    \n",
    "    pred = np.zeros(test_data.shape[0])\n",
    "    pred[test_data[:,22] >= 2] = test_sets_expanded[2] @ models[2]\n",
    "    pred[test_data[:,22] == 1] = test_sets_expanded[1] @ models[1]\n",
    "    pred[test_data[:,22] == 0] = test_sets_expanded[0] @ models[0]\n",
    "    decision = 0\n",
    "    pred[np.where(pred <  decision)] = -1\n",
    "    pred[np.where(pred >= decision)] = 1\n",
    "    return pred\n",
    "\n",
    "prediction = make_predictions(jet_sets_test, [degree0, degree1, degree2], [model0, model1, model2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6819a8a9-ebed-461e-bc42-c3415a5b662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, prediction, \"Erwin2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
