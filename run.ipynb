{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a3a65fb-8def-459a-86ff-14f5cf3bc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from implementations import *\n",
    "from helpers import load_csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c729a004-595c-4d58-bbcb-b0f304e22f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8fb42fca-b128-48c4-891b-14abf08cb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_data, train_ids = load_csv_data(\"data/train.csv\")\n",
    "_, test_data, test_ids = load_csv_data(\"data/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ba899f82-6863-44cb-acd3-0aee5f4e52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mean = train_data.mean(axis=0)\n",
    "train_data_std = train_data.std(axis=0)\n",
    "x = (train_data - train_data_mean)/train_data_std\n",
    "test_x = (test_data - train_data_mean)/train_data_std\n",
    "y = train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a3dcd-aaa0-46dd-b54e-e2a6329012fd",
   "metadata": {},
   "source": [
    "functions to test different methods for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fdbe4f29-56e7-4f6d-b3d3-8e9b5b0b04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, model):\n",
    "    err = y - (tx @ model)\n",
    "    return (err.T @ err)/y.shape[0]\n",
    "\n",
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\n",
    "    \n",
    "    Args:\n",
    "        y:      shape=(N,)\n",
    "        k_fold: K in K-fold, i.e. the fold num\n",
    "        seed:   the random seed\n",
    "\n",
    "    Returns:\n",
    "        A 2D array of shape=(k_fold, N/k_fold) that indicates the data indices for each fold\n",
    "\n",
    "    >>> build_k_indices(np.array([1., 2., 3., 4.]), 2, 1)\n",
    "    array([[3, 2],\n",
    "           [0, 1]])\n",
    "    \"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\n",
    "    \n",
    "    Args:\n",
    "        x: numpy array of shape (N,D)\n",
    "        degree: integer.\n",
    "        \n",
    "    Returns:\n",
    "        poly: numpy array of shape (N,D*d+1)\n",
    "    \"\"\"    \n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    #poly_base = np.zeros((N, D*degree + 1))\n",
    "    poly_base = np.ones((N,1))\n",
    "    poly_base = np.hstack((poly_base, x.copy()))\n",
    "    for i in range(degree-1):\n",
    "        range_start = 1 + i*D\n",
    "        range_stop = 1 + (i+1)*D\n",
    "        next_power = poly_base[:,range_start:range_stop]*x\n",
    "        poly_base = np.hstack((poly_base, next_power))\n",
    "    \n",
    "    return poly_base\n",
    "\n",
    "def cross_validation(train_model, degree):\n",
    "    \"\"\"\n",
    "    Tests a certain training function using 4-fold cross-validation\n",
    "    arguments: \n",
    "    train_model: func(y, tx) -> model\n",
    "    returns: model, training_loss, test_loss\n",
    "    \"\"\"\n",
    "    tx = build_poly(x, degree)\n",
    "    k = 4\n",
    "    k_indices = build_k_indices(train_y, k, seed)\n",
    "    test_idx = k_indices[k-1]\n",
    "    train_idx = (k_indices[:k-1]).flatten()\n",
    "    model, train_loss = train_model(y[train_idx], tx[train_idx])\n",
    "    test_loss = compute_loss(y[test_idx], tx[test_idx], model)\n",
    "    return model, train_loss, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f2073-be82-49c6-9b9b-1445a1baaf91",
   "metadata": {},
   "source": [
    "Graph stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6dcf262e-d3ff-471e-9e97-17b158776551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cross_validation_visualization(lambds, mse_tr, mse_te):\n",
    "    \"\"\"visualization the curves of mse_tr and mse_te.\"\"\"\n",
    "    plt.semilogx(lambds, mse_tr, marker=\".\", color='b', label='train error')\n",
    "    plt.semilogx(lambds, mse_te, marker=\".\", color='r', label='test error')\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"r mse\")\n",
    "    #plt.xlim(1e-4, 1)\n",
    "    plt.title(\"cross validation\")\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"cross_validation\")\n",
    "    \n",
    "def cross_validation_explore_lambda(train_model, degree, lambdas):\n",
    "    \"\"\"cross validation over regularisation parameter lambda.\n",
    "    \n",
    "    Args:\n",
    "        train_model: func(y, tx, lambda) -> model\n",
    "        degree: integer, degree of the polynomial expansion\n",
    "        lambdas: shape = (p, ) where p is the number of values of lambda to test\n",
    "    Returns:\n",
    "        best_lambda : scalar, value of the best lambda\n",
    "        best_mse : scalar, the associated mean squared error for the best lambda\n",
    "    \"\"\"\n",
    "    seed = 12\n",
    "    degree = degree\n",
    "    lambdas = lambdas\n",
    "    # define lists to store the loss of training data and test data\n",
    "    mse_tr = []\n",
    "    mse_te = []\n",
    "    \n",
    "    best_idx = 0\n",
    "    idx = 0\n",
    "    for lambda_ in np.nditer(lambdas):\n",
    "        _, te, tr = cross_validation(lambda y,tx: train_model(y,tx, lambda_), degree)\n",
    "        mse_tr.append(tr)\n",
    "        mse_te.append(te)\n",
    "        if te < mse_te[best_idx]:\n",
    "            best_idx = idx\n",
    "        idx += 1\n",
    "    \n",
    "    best_lambda = lambdas[best_idx]\n",
    "    best_mse = mse_te[best_idx]\n",
    "        \n",
    "    cross_validation_visualization(lambdas, mse_tr, mse_te)\n",
    "    print(\"For polynomial expansion up to degree %.f, the choice of lambda which leads to the best test mse is %.5f with a test mse of %.3f\" % (degree, best_lambda, best_mse))\n",
    "    return best_lambda, best_mse\n",
    "\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "#best_lambda, best_rmse = cross_validation_demo(7, 4, np.logspace(-4, 0, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ca23c-c1ac-4785-93b3-f324f71a9efe",
   "metadata": {},
   "source": [
    "Now try different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e9ebb8fe-4d8d-446e-8d55-17ec3da49300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-4.45304550e+03,  8.64846646e-02, -2.43657221e-01, -2.41641346e-01,\n",
       "         1.18422980e-01, -1.47201046e+04,  3.79406884e-02,  1.36063684e+03,\n",
       "         2.68124417e-01, -1.35710250e-02, -2.57282077e+02, -1.87218726e-01,\n",
       "         5.38064206e-02,  2.03773787e+04,  5.00541573e+01, -1.13227276e-03,\n",
       "         1.92713269e-04,  4.93056675e+01,  4.96668781e-04,  9.14434997e-04,\n",
       "         4.75368576e-02,  2.18275446e-03, -3.79968526e-02,  3.14001763e+04,\n",
       "         1.94578616e+00, -1.63052605e+04, -2.37205201e+02,  3.06500002e-01,\n",
       "        -2.16379340e+04,  9.58845737e+02,  2.17898803e+02,  3.78063163e-02,\n",
       "         3.64114507e-02,  5.95306023e-03,  7.71002751e-03,  4.69456425e+03,\n",
       "        -1.11906469e-02, -4.39827442e+02, -5.83697764e-02,  2.23967611e-03,\n",
       "        -9.08764862e-03,  2.03170056e-02,  5.85812603e-02, -6.45995214e+03,\n",
       "        -1.78836558e-02, -3.29401946e-02, -3.03005306e-03, -2.31037648e-02,\n",
       "        -5.71582613e-02, -2.06890845e-03, -7.99635408e-03,  4.40089202e-04,\n",
       "        -1.98167846e-02, -1.00904107e+04, -8.01243499e-01,  9.99254678e+03,\n",
       "         1.45555103e+02,  1.26299696e-01,  6.91749571e+03, -3.06503967e+02,\n",
       "         1.21047216e-02]),\n",
       " 0.3167029658464651,\n",
       " 0.6455531446063242)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(least_squares,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98042de-c114-4778-aaa4-5e7e88216a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_explore_lambda(lambda y,tx,lambda_: ridge_regression(y,tx,lambda_), 3, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e92c7e36-e536-40c2-b099-eed4569f3492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-8.05291911e-02,  2.17067256e-02, -3.22149173e-02, -1.26231262e-03,\n",
       "         1.65392468e-02,  1.13124218e-02,  1.61151151e-02,  1.12084660e-02,\n",
       "         2.09079318e-03, -2.08117141e-03,  1.24262748e-02, -1.82336961e-02,\n",
       "         2.44234779e-02,  1.12837765e-02,  2.12926998e-02,  8.52438106e-06,\n",
       "        -4.54075796e-04, -3.30284901e-03, -1.78764076e-06,  3.97694330e-04,\n",
       "         1.50958797e-03,  6.91787073e-04,  1.08647655e-02,  1.05152289e-02,\n",
       "         1.32004359e-02,  1.26264709e-02,  1.26253124e-02,  1.12036398e-02,\n",
       "         1.12762249e-02,  1.12751909e-02,  1.05438203e-02]),\n",
       " 0.5761583841141812,\n",
       " 0.882165687969785)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(lambda y,tx: logistic_regression(y, tx, np.zeros(tx.shape[1]), 100, 0.001), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
