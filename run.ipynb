{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3a65fb-8def-459a-86ff-14f5cf3bc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from implementations import *\n",
    "from helpers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c729a004-595c-4d58-bbcb-b0f304e22f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb42fca-b128-48c4-891b-14abf08cb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_raw, train_data_raw, train_ids = load_csv_data(\"data/train.csv\")\n",
    "_, test_data_raw, test_ids = load_csv_data(\"data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8226b5-292a-4fea-9a8e-63294246442e",
   "metadata": {},
   "source": [
    "## Data cleaning and grouping\n",
    "This part creates three sets of rows depending on the number of jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5b771a-a00b-4249-b904-7e65483e7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_over = train_data_raw[train_data_raw[:,0] != -999]\n",
    "med_DER_mass_MMC = np.median(med_over[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c8c699-642d-4806-bb8f-d0da7a56dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_raw[train_data_raw[:,0] > -999].copy()\n",
    "means = np.nanmean(train_data, axis=0)\n",
    "inds = np.where(np.isnan(train_data))\n",
    "train_data[inds] = np.take(means, inds[1])\n",
    "\n",
    "train_labels = train_labels_raw[train_data_raw[:,0] > -999].copy()\n",
    "\n",
    "test_data = test_data_raw.copy()\n",
    "test_data[test_data_raw[:,0] == -999] = med_DER_mass_MMC\n",
    "inds = np.where(np.isnan(test_data))\n",
    "test_data[inds] = np.take(means, inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55538e76-e371-4d6f-ae76-03c72ed0736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_more_jets = train_data[train_data[:,22] >= 2].copy()\n",
    "one_jet = train_data[train_data[:,22] == 1].copy()\n",
    "one_jet = np.delete(one_jet, np.s_[4,5,6,12,22,26,27,28,29], axis=1)\n",
    "zero_jet = train_data[train_data[:,22] == 0].copy()\n",
    "zero_jet = np.delete(zero_jet, np.s_[4,5,6,12,22,23,24,25,26,27,28,29], axis=1)\n",
    "\n",
    "jet_sets = [zero_jet, one_jet, two_more_jets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b4f370-0be2-429e-9e51-ff82f84948c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_more_jets = train_labels[train_data[:,22] >= 2].copy()\n",
    "one_jet = train_labels[train_data[:,22] == 1].copy()\n",
    "zero_jet = train_labels[train_data[:,22] == 0].copy()\n",
    "\n",
    "jet_sets_labels = [zero_jet, one_jet, two_more_jets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f6220d-8c59-40d6-b8ea-66992b8bdf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_more_jets_test = test_data[test_data[:,22] >= 2].copy()\n",
    "one_jet_test = test_data[test_data[:,22] == 1].copy()\n",
    "one_jet_test = np.delete(one_jet_test, np.s_[4,5,6,12,22,26,27,28,29], axis=1)\n",
    "zero_jet_test = test_data[test_data[:,22] == 0].copy()\n",
    "zero_jet_test = np.delete(zero_jet_test, np.s_[4,5,6,12,22,23,24,25,26,27,28,29], axis=1)\n",
    "\n",
    "\n",
    "jet_sets_test = [zero_jet_test, one_jet_test, two_more_jets_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba182e-44e4-492d-baf4-af3d4a169dcf",
   "metadata": {},
   "source": [
    "### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba899f82-6863-44cb-acd3-0aee5f4e52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    mean = jet_sets[i].mean(axis=0)\n",
    "    std = jet_sets[i].std(axis=0)\n",
    "    jet_sets[i] = (jet_sets[i] - mean)/std\n",
    "    jet_sets_test[i] = (jet_sets_test[i] - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7752cf4-a4c3-4eef-98ef-4288ac8d1c6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a3dcd-aaa0-46dd-b54e-e2a6329012fd",
   "metadata": {},
   "source": [
    "functions to test different methods for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdbe4f29-56e7-4f6d-b3d3-8e9b5b0b04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, model):\n",
    "    \"\"\"\n",
    "    compute the proportion of misprediction\n",
    "    \"\"\"\n",
    "    pred = tx @ model\n",
    "    decision = 0\n",
    "    pred[np.where(pred <  decision)] = -1\n",
    "    pred[np.where(pred >= decision)] = 1\n",
    "    err = (pred - y)/2\n",
    "    return np.absolute(err).mean()\n",
    "\n",
    "def build_validation_sets(y, k_fold, seed):\n",
    "    \"\"\"\n",
    "    returns indices for a train set and a test set\n",
    "    \"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    return indices[indices.shape[0]//(k_fold+1):], indices[:indices.shape[0]//(k_fold+1)],\n",
    "\n",
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\n",
    "    \n",
    "    Args:\n",
    "        x: numpy array of shape (N,D)\n",
    "        degree: integer.\n",
    "        \n",
    "    Returns:\n",
    "        poly: numpy array of shape (N,D*d+1)\n",
    "    \"\"\"    \n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "    #poly_base = np.zeros((N, D*degree + 1))\n",
    "    poly_base = np.ones((N,1))\n",
    "    poly_base = np.hstack((poly_base, x.copy()))\n",
    "    for i in range(degree-1):\n",
    "        range_start = 1 + i*D\n",
    "        range_stop = 1 + (i+1)*D\n",
    "        next_power = poly_base[:,range_start:range_stop]*x\n",
    "        poly_base = np.hstack((poly_base, next_power))\n",
    "    \n",
    "    return poly_base\n",
    "\n",
    "def cross_validation(y, x, train_model, degree):\n",
    "    \"\"\"\n",
    "    Tests a certain training function using 4-fold cross-validation\n",
    "    arguments: \n",
    "    train_model: func(y, tx) -> model\n",
    "    returns: model, training_loss, test_loss\n",
    "    \"\"\"\n",
    "    tx = build_poly(x, degree)\n",
    "    k = 4\n",
    "    train_idx, test_idx = build_validation_sets(x, k, seed)\n",
    "    model, train_loss = train_model(y[train_idx], tx[train_idx])\n",
    "    test_loss = compute_loss(y[test_idx], tx[test_idx], model)\n",
    "    return model, train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7976330-0c73-40a8-b4c3-24c6aed3aa41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3411996011080886, 0.24999410057342425)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_all = 2\n",
    "model_all, train_loss, test_loss = cross_validation(train_labels, train_data,least_squares, degree_all)\n",
    "train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ebb8fe-4d8d-446e-8d55-17ec3da49300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21554411166824772"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree0 = 1\n",
    "model0, train_loss, test_loss = cross_validation(jet_sets_labels[0], jet_sets[0],least_squares, degree0)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f49995bf-9b34-4e80-a426-ea6b4e89f118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22863675335810232"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree1 = 6\n",
    "model1, train_loss, test_loss = cross_validation(jet_sets_labels[1], jet_sets[1],least_squares,degree1)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9de94960-840e-4bbf-8e38-deb4ac9b29f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20305388342387315"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree2 = 4\n",
    "model2, train_loss, test_loss = cross_validation(jet_sets_labels[2], jet_sets[2],least_squares, degree2)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4cf158-a6ca-4b9f-9188-ab0b13d6dcb1",
   "metadata": {},
   "source": [
    "### Not doing cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be5fc48a-9c30-46d3-9326-4a8dac1649f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0,_ = least_squares(jet_sets_labels[0], build_poly(jet_sets[0], degree0))\n",
    "model1,_ = least_squares(jet_sets_labels[1], build_poly(jet_sets[1], degree1))\n",
    "model2,_ = least_squares(jet_sets_labels[2], build_poly(jet_sets[2], degree2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8659ee-f4c9-4539-bd39-c8ba83b8b1ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Applying the models to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95758cb2-802f-40a9-b6c6-a3cdbe3d1f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_predictions(test_sets, degrees, models):\n",
    "    assert test_data.shape[0] == test_sets[0].shape[0] + test_sets[1].shape[0] + test_sets[2].shape[0]\n",
    "    test_sets_expanded = {}\n",
    "    for i in range(3):\n",
    "        test_sets_expanded[i] = build_poly(test_sets[i], degrees[i])\n",
    "    \n",
    "    pred = np.zeros(test_data.shape[0])\n",
    "    pred[test_data[:,22] >= 2] = test_sets_expanded[2] @ models[2]\n",
    "    pred[test_data[:,22] == 1] = test_sets_expanded[1] @ models[1]\n",
    "    pred[test_data[:,22] == 0] = test_sets_expanded[0] @ models[0]\n",
    "    decision = 0\n",
    "    pred[np.where(pred <  decision)] = -1\n",
    "    pred[np.where(pred >= decision)] = 1\n",
    "    return pred\n",
    "\n",
    "prediction = make_predictions(jet_sets_test, [degree0, degree1, degree2], [model0, model1, model2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6819a8a9-ebed-461e-bc42-c3415a5b662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, prediction, \"data/Erwin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
